
@{
    ViewBag.Title = "googleseo";
    Layout = "~/Views/Shared/_Layout.cshtml";
}

<div class="content">
    <h1>Google CEO Pichai says Gemini's AI image results "offended our users"</h1>
    <img src="~/Content/img/BIDEN.jpg" alt="">
    <div class="description">
        <p style="width: 50%; font-size: 20px; line-height: 2.2; width:70%; ">
            Google CEO Sundar Pichai told employees in an internal memo late Tuesday that the company's release of artificial intelligence tool Gemini has been unacceptable, pledging to fix and relaunch the service in the coming weeks.

            Last week, Google paused Gemini's ability to create images following viral posts on social media depicting some of the AI tool's results, including images of America's Founding Fathers as black, the Pope as a woman and a Nazi-era German solider with dark skin.

            The tool often thwarted requests for images of white people, prompting a backlash online among conservative commentators and others, who accused Google of anti-white bias.

            Still reeling from the controversy, Pichai told Google staff in a note reviewed by NPR that there is no excuse for the tool's "problematic" performance.

            "I know that some of its responses have offended our users and shown bias — to be clear, that's completely unacceptable and we got it wrong," Pichai wrote. "We'll be driving a clear set of actions, including structural changes, updated product guidelines, improved launch processes, robust evals and red-teaming, and technical recommendations."

            Google executive pins blame on 'fine-tuning' error
            In a blog post published Friday, Google explained that when it built Gemini's image generator, it was fine-tuned to try to avoid the pitfalls of previous ones that created violent or sexually explicit images of real people.

            As part of that process, creating diverse images was a focus, or as Google put it, building an image tool that would "work well for everyone" around the world.

            "If you ask for a picture of football players, or someone walking a dog, you may want to receive a range of people. You probably don't just want to only receive images of people of just one type of ethnicity (or any other characteristic)," wrote Google executive Prabhakar Raghavan.

            But, as Raghavan wrote, the effort backfired. The AI service "failed to account for cases that should clearly not show a range. And second, over time, the model became way more cautious than we intended and refused to answer certain prompts entirely — wrongly interpreting some very anodyne prompts as sensitive."

            Researchers have pointed out that Google was trying to counter images that perpetuate bias and stereotype, since many large datasets of images have been found to contain mostly white people, or are replete with one type of image, like, for example, depicting most doctors as male.

            In attempting to avoid a public relations crisis about gender and race, Google managed to run headlong into another controversy over accuracy and history.

            Text responses also prompt controversy
            Gemini, which was previously named Bard, is also an AI chatbot, similar to OpenAI's hit service ChatGPT.

            The text-generating capabilities of Gemini also came under scrutiny after several outlandish responses went viral online.

            Elon Musk shared a screenshot of a question one user asked: "Who has done more harm: libertarians or Stalin?"

            Gemini responded: "It is difficult to say definitively which ideology has done more harm, both have had negative consequences."

            The answer appears to have been fixed. Now, when the Stalin question is posed to the chatbot, it replies: "Stalin was directly responsible for the deaths of millions of people through orchestrated famines, executions, and the Gulag labor camp system."

            Google's Pichai: "No AI is perfect"
            Gemini, like ChatGPT, is known as a large language model. It is a type of AI technology that predicts the next word or sequence of words based on an enormous dataset compiled from the internet. But what Gemini, and early versions of ChatGPT, have illustrated is that the tools can produce unforeseeable and sometimes unsettling results that even the engineers working on the advanced technology cannot always predict ahead of a tool's public launch.

            Big Tech companies, including Google, have for years been studying AI image generators and large language models secretly in labs. But OpenAI's unveiling of ChatGPT in late 2022 set of an AI arms race in Silicon Valley, with all the major tech firms attempting to release their own versions to stay competitive.

            In his note to employees at Google, Pichai wrote that when Gemini is re-released to the public, he hopes the service is in better shape.

            "No AI is perfect, especially at this emerging stage of the industry's development, but we know the bar is high for us and we will keep at it for however long it takes," Pichai wrote.
        </p>
    </div>
</div>

